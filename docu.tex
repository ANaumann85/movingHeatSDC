\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[utf8]{inputenc}
\usepackage[ruled,algo2e,linesnumbered,algonl]{algorithm2e}
\usepackage{color}

\newtheorem{remark}{Remark}
\newtheorem{lemma}{Lemma}
\newcommand{\ve}[1]{\mathbf{#1}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO -- #1]}}

\bibliographystyle{plain}

\bibliography{refs}
\begin{document}
\section*{Multi-rate spectral deferred corrections}
Consider a single time step $[T_{n}, T_{n+1}]$.
Now denote as $t_m$, $m=1, \ldots, M$ with $T_{n} \leq t_1 < \ldots < t_{M} \leq T_{n+1}$ a set of quadrature nodes in this time step.
Denote as $l_m$, $m=1, \ldots, M$ the Lagrange polynomials satisfying 
\begin{equation}
	l_m(t_j) = \delta_{m,j} \ \text{for} \ m,j=1, \ldots, M.
\end{equation}
In each sub step $[t_m, t_{m+1}]$, place a set of embedded nodes $t_{m,p}$, $m=1,\ldots,M$, $p=1,\ldots,P$ with $t_{m} \leq t_{m,1} < \ldots < t_{m,P} \leq t_{m}$.
Denote as $l_{m,p}$ the Lagrange polynomials for an embedded set of quadrature nodes satisfying
\begin{equation}
	l_{m,p}(t_{m,q}) = \delta_{p,q} \ \text{for} \ p,q=1,\ldots,P.
\end{equation}
\begin{remark}
We refer to nodes and weights associated with $t_m$ as \textbf{standard} and use indices $m$ and $j$.
Nodes and weights associated with an embedded quadrature rule are called \textbf{embedded} and indexed with $p$ and $q$.
\end{remark}
Note that there are $M$ many standard nodes, polynomials and weights and $M \times P$ many embedded nodes, polynomials and weights.
\begin{remark}
We assume that for both standard and embedded quadrature rules, the right endpoint is a quadrature nodes, so that $t_{M} = T_{n+1}$ and $t_{m,P} = t_{m+1}$.
\end{remark}
\begin{remark}
However, to allow for Radau-type rules, we do \textbf{not} require that the left endpoint matches the first quadrature nodes and typically we will have $T_n < t_1$ as well as $t_{m} < t_{m,1}$.
To simplify notation, we use the following conventions
\begin{equation}
	t_0 := T_n \ \text{and} \ t_{m,0} := t_{m}.
\end{equation}
\end{remark}

\subsection*{Weights.}
We need three different sets of quadrature weights.
First the standard weights
\begin{equation}
	s_{m,j} := \int_{t_{m-1}}^{t_{m}} l_{j}(s)~ds, \ \text{for} \ m,j=1,\ldots,M.
\end{equation}
For the embedded weights we need
\begin{equation}
	s_{m,p,q} := \int_{t_{m,p-1}}^{t_{m,p}} l_{m,q}(s)~ds, \ \text{for} \ m=1,\ldots,M, \ p,q=1,\ldots,P.
\end{equation}
To approximate integration of a function given at the embedded nodes over a standard sub-step, the embedded weights need to be summed up
\begin{equation}
	\hat{s}_{m,q} := \int_{t_{m-1}}^{t_{m}} l_{m,q}(s)~ds = \sum_{p=1}^{P} \int_{t_{m,p-1}}^{t_{m,p}} l_{m,q}(s)~ds = \sum_{p=1}^{P} s_{m,p,q}
\end{equation}
for $m=1,\ldots,M$ and $q=1,\ldots,P$.
We also need the following \textbf{mixed} weights for integrating the Lagrange polynomials for the standard weights over sub steps associated with embedded quadrature rules
\begin{equation}
	\tilde{s}_{m,p,j} := \int_{t_{m,p-1}}^{t_{m,p}} l_{j}(s)~ds, \ \text{for} \ m,j=1,\ldots,M, \ p=1,\ldots,P.
\end{equation}
\begin{lemma}\label{lemma:weights_match}
The mixed weights are consistent with the standard weights in the sense that
\begin{equation}
	s_{m,j} = \int_{t_{m-1}}^{t_{m}} l_j(s)~ds = \sum_{p=1}^{P} \int_{t_{m,p-1}}^{t_{m,p}} l_j(s)~ds = \sum_{p=1}^{P} \tilde{s}_{m,p,j}.
\end{equation}
Verified by \texttt{test\_weights\_match}.
\end{lemma}

\begin{table}[h]
\centering
\begin{tabular}{|cc|cc|} \hline
\multicolumn{2}{|c|}{Function values} & \multicolumn{2}{c|}{Integral} \\ \hline
&          & Standard        & Embedded            \\ \hline
& Standard & $s_{m,j}$       & $\tilde{s}_{m,p,j}$ \\
& Embedded & $\hat{s}_{m,q}$ & $s_{m,p,q}$ \\ \hline
\end{tabular}
\caption{Quadrature weights for integrals over standard or embedded sub steps depending on whether function values are given at standard or embedded nodes.}
\end{table}

\subsection*{Quadrature rules.}
Denote as $\ve{u}^{s}$ (``standard'') a vector with $M$ approximate solutions at the standard nodes and as $\ve{u}^{e}$ (``embedded'') a vector composed of $M$ vectors $\ve{u}^{e}_{m}$, $m=1,\ldots,M$ with each $\ve{u}^{e}_{m}$ containing $P$ approximate solutions at the embedded nodes $t_{m,p}$, $p=1, \ldots, P$.
We will need the following three integration operators:
\begin{equation}
	\int_{t_{m-1}}^{t_{m}} u(s)~ds \approx I_{m-1}^{m}(\ve{u}^s, \ve{u}^{e}_{m}) := \sum_{j=1}^{M} s_{m,j} \ve{u}^{s}_{j} + \sum_{p=1}^{P} \hat{s}_{m,p} \ve{u}^{e}_{m,p}.
\end{equation}
Here, $\ve{u}^{s}_{j}$ denotes the $j$\textsuperscript{th} entry in $\ve{u}^{s}$ while $\ve{u}^{e}_{m,p}$ is the $p$\textsuperscript{th} entry in $\ve{u}^{e}_{m}$.
\begin{remark}
Test \texttt{...} verifies this identity for linear functions.
\end{remark}
Furthermore, we can approximate the integral over an embedded sub step by
\begin{equation}
	\int_{t_{m,p-1}}^{t_{m,p}} u(s)~ds \approx I_{m,p-1}^{p}(\ve{u}^s, \ve{u}^{e}_{m}) := \sum_{j=1}^{M} \tilde{s}_{m,p,j} \ve{u}^{s}_{j} + \sum_{q=1}^{P} s_{m,p,q} \ve{u}^{e}_{m,q}.
\end{equation}
\begin{lemma}\label{lemma:quadrature_match}
The two integration operators are consistent in the sense that
\begin{equation}
	I_{m-1}^{m}(\ve{u}^s, \ve{u}^{e}_{m}) = \sum_{p=1}^{P} I_{m,p-1}^{p}(\ve{u}^s, \ve{u}^{e}_{m}).
\end{equation}
\begin{proof}
By definition of the operators and $\hat{s}_{m,q}$ and using Lemma~\ref{lemma:weights_match} it holds that
\begin{align*}
	\sum_{p=1}^{P} I_{m,p-1}^{p}(\ve{u}^s, \ve{u}^{e}_{m}) &= \sum_{p=1}^{P} \left( \sum_{j=1}^{M} \tilde{s}_{m,p,j} \ve{u}^{s}_j + \sum_{q=1}^{P} s_{m,p,q} \ve{u}^{e}_{m,q} \right) \\
		&= \sum_{j=1}^{M} \left( \sum_{p=1}^{P} \tilde{s}_{m,p,j} \right) \ve{u}^{s}_{j} + \sum_{q=1}^{P} \left( \sum_{p=1}^{P} s_{m,p,q} \right) \ve{u}^{e}_{m,q} \\
		&= \sum_{j=1}^{M} s_{m,j} \ve{u}^{s}_{j} + \sum_{q=1}^{P} \hat{s}_{m,q} \ve{u}^{e}_{m,q} = I_{m-1}^{m}(\ve{u}^s, \ve{u}^{e}_{m})
\end{align*}
\end{proof}
\end{lemma}
%
%
%
\paragraph{Matrix formulation.}
To represent the above quadrature rules in matrix form, define the following four matrices
\begin{align*}
	\ve{S} &:= \left( s_{m,j} \right) \in \mathbb{R}^{M,M} \ \text{for} \ m,j=1,\ldots,M \\ 
	\hat{\ve{S}} &:= \left( \hat{s}_{m,p} \right) \in \mathbb{R}^{M,P} \ \text{for} \ m=1,\ldots,M, \ p=1,\ldots,P \\
	\tilde{\ve{S}}_m &:= \left( \tilde{s}_{m,p,j} \right) \in \mathbb{R}^{P,M} \ \text{for} \ \ p=1,\ldots,P, \ j=1,\ldots,M \\
	\ve{S}_m &:= \left( s_{m,p,q} \right) \in \mathbb{R}^{P,P} \ \text{for} \ p,q=1,\ldots,P.
\end{align*}
We can write the integrals over standard sub steps as
\begin{equation}
	\ve{I}^s := 
	\begin{bmatrix}
		I_{0}^1 \\ I_1^2 \\ \vdots \\ I_{M-1}^{M}
	\end{bmatrix}
	=
	\ve{S} \ve{u}^s +
	\begin{bmatrix}
		\hat{\ve{S}}[1,:] & & \\ & \hat{\ve{S}}[2,:] \\ & & \ddots \\ & & & \hat{\ve{S}}[M,:] 
	\end{bmatrix}
	\begin{bmatrix}
		\ve{u}^e_1 \\ \ve{u}^e_2 \\ \vdots \\ \ve{u}^{e}_{M}
	\end{bmatrix}.
\end{equation}
Integrals over embedded steps can be written as
\begin{equation}
	\ve{I}^e_m :=
	\begin{bmatrix}
		I_{m,0}^{1} \\ I_{m,1}^{2} \\ \vdots \\ I_{m,P-1}^{P}
	\end{bmatrix}
	=
	\tilde{\ve{S}}[m,:,:] \ve{u}^s + \ve{S}[m,:,:] \ve{u}^e_m, \ \text{for} \ m=1,\ldots,M
\end{equation}
so that
\begin{equation}
	\ve{I}^e = 
	\begin{bmatrix}
		\ve{I}^e_1 \\ \ve{I}^e_2 \\ \vdots \\ \ve{I}^e_M
	\end{bmatrix} = 
	\begin{bmatrix}
		\tilde{\ve{S}}[1,:,:] \\ \tilde{\ve{S}}[2,:,:]  \\ \vdots \\ \tilde{\ve{S}}[M,:,:] 
	\end{bmatrix}
	\ve{u}^s
	+
	\begin{bmatrix}
		\ve{S}[1,:,:] \\ \ve{S}[2,:,:] \\ \vdots \\ \ve{S}[M,:,:] 
	\end{bmatrix}
	\begin{bmatrix}
		\ve{u}^e_1 \\ \ve{u}^e_2 \\ \vdots \\ \ve{u}^e_M.
	\end{bmatrix}
\end{equation}
%
%
%
\subsection*{Multi-rate SDC sweeps}
Consider an initial value problem
\begin{equation}
	\dot{u}(t) = f(u(t)) + g(u(t))
\end{equation}
where we want to integrate $f$ implicitly with a large time step and $g$ explicitly with a small time step.
As before, denote as $\ve{u}^s$ a vector with approximate solutions at the standard nodes and as $\ve{u}^{e}$ the vector with approximate solutions at the embedded nodes.
The predictor computes the initial set of values
\begin{itemize}
	\item Compute standard step
	\begin{equation*}
		u^*_{m} = u^0_{m-1} + \Delta t_m f(u^*_{m})
	\end{equation*}
	\item Compute $P$ embedded steps
	\begin{equation*}
		u^0_{m-1,p} = u^0_{m-1,p-1} + \Delta t_{m,p} f(u^*_{m}) + \Delta t_{m,p} g(u^0_{m-1,p-1})
	\end{equation*}
	\item Set $u^0_{m} = u^0_{m-1,P}$ for use as initial value in next standard step.
\end{itemize}

Given values $f(u^k_m)$ and $g(u^k_{m,p})$, the multi-rate SDC sweep then consists of
\begin{itemize}
\item Compute standard step
	\begin{equation}
		u^{*}_{m} = u^{k+1}_{m-1} + \Delta t_m \left( f(u^{*}_{m}) - f(u^k_{m}) \right) + I_{m-1}^{m} \left( f(\ve{u}^{s,k}) , g(\ve{u}^{e,k}_m) \right)
	\end{equation}
\item Compute $P$ embedded steps
	\begin{align*}
		u_{m-1,p}^{k+1} = u_{m-1,p-1}^{k+1} &+ \Delta t_{m,p} \left( f(u^{*}_{m}) - f(u^k_{m}) \right) \\
			& + \Delta t_{m,p} \left( g(u^{k+1}_{m-1,p-1}) - g(u^k_{m-1,p-1}) \right) \\
			& + I_{m,p-1}^{p}  \left( f(\ve{u}^{s,k}) , g(\ve{u}^{e,k}_m) \right)
	\end{align*}
	for $p=1, \ldots, P$.
\item Set $u_{m}^{k+1} = u_{m-1,P}^{k+1}$ for use as initial value in next standard step.
\end{itemize}
\begin{remark}
If the iteration converges, that is and $u^{k+1}_{m} - u^{k}_{m} \to 0$ and $u^{k+1}_{m,p} - u^{k}_{m,p} \to 0$, the sweeps reduce to the underlying collocation equations
\begin{equation}
	u_{m} = u_{m-1} + I_{m-1}^{m} \left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right)
\end{equation}
and
\begin{equation}
	u_{m,p} = u_{m,p-1} + I_{m,p-1}^{p} \left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right)
\end{equation}
Based on this, for given values of $\ve{u}^s$, $\ve{u}^3$, we can define the standard 
\begin{equation}
 r^s := \max_{m=1,\ldots,M} \left\| \ve{u}^s_{m} - \ve{u}^s_{m-1} - I_{m-1}^{m}\left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right) \right\|
\end{equation}
and embedded residual
\begin{equation}
	r^e := \max_{m=1,\ldots,M} \max_{p=1,\ldots,P} \left\| \ve{u}^e_{m,p} - \ve{u}^e_{m,p-1} - I_{m,p-1}^{p}\left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right) \right\|.
\end{equation}
\end{remark}
%
%
%
\begin{lemma}
The collocation solution is invariant under SDC sweeps. Let $\ve{u}^s$ and $\ve{u}^e$ satisfy the collocation condition.
Then,
\begin{align*}
	u^{k+1}_{m} &= u_{m-1}  + \Delta t_m \left( f(u^{k+1}_m) - f(u_m) \right) + I_{m-1}^{m}\left( f(\ve{u}^s, g(\ve{u}^e_m) \right) \\
		&= u_{m} + \Delta t_{m} \left( f(u^{k+1}_m) - f(u_m) \right) \\
	\Rightarrow u^{k+1}_m - \Delta t_m f(u^{k+1}_{m}) &= u_{m} - \Delta t_{m} f(u_m)
\end{align*}
so that $u^{k+1}_m = u_m$.
The embedded sweep will then give
\begin{align*}
	u^{k+1}_{m,p} &= u_{m,p-1} + \Delta t_{m,p} \left( g(u^{k+1}_{m-1,p-1}) - g(u_{m-1,p-1} \right) + I_{m,p-1}^{p} \left( f(\ve{u}^s, g(\ve{u}^e_m) \right) \\
				&= u_{m,p} - \Delta t_{m,p} \left( g(u^{k+1}_{m-1,p-1}) - g(u_{m-1,p-1}) \right)
\end{align*}
so that $u^{k+1}_{m,p} = u_{m,p}$.
Finally,
\begin{equation}
	u_{m} = u_{m-1,P} = u_{m-1,0} + \sum_{p=1}^{P} I_{m,p-1}^{p}\left( f(\ve{u}^s, g(\ve{u}^e_m) \right) = u_{m-1} + I_{m-1}^{m}\left( f(\ve{u}^s, g(\ve{u}^e_m) \right) 
\end{equation}
so that overwriting $u_{m}$ with $u_{m-1,P}$ does not modify the value.
\end{lemma}
%
%
%
\begin{lemma}
The collocation solutions are consistent in the sense that
\begin{align*}
	u_{m,P} &= u_{m-1,P-1} + I_{m,P-1}^{P}\left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right) \\
			&= \ldots = u_{m-1,0} + \sum_{p=1}^{P} I_{m,p-1}^{p}\left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right) \\
			&= u_{m-1} + I_{m-1}^{m}\left( f(\ve{u}^{s}) , g(\ve{u}^{e}_m) \right) = u_{m}
\end{align*}
using Lemma~\ref{lemma:quadrature_match}.
\end{lemma}
%
%
\begin{remark}
For approximations of the collocation solution, this consistency criterion is not satisfied and typically
\begin{equation}
	u_{m}^{k} \neq u_{m,P}^{k}.
\end{equation}
\end{remark}

\paragraph{A comment on updates.}
Instead of simply overwriting $u^{k+1}_{m}$ with $u^{k+1}_{m-1,P}$ in the multi-rate SDC sweep, it is possible to compute the proper collocation update
\begin{equation}
	u^{k+1}_{m} = u^{k+1}_{m-1} + \sum_{p=1}^{P} q_{m, p} f(u^{k+1}_{m,p})
\end{equation}
with weights
\begin{equation}
	q_{m,p} := \int_{t_{m-1}}^{t_{m}} l_{m,p}(s)~ds.
\end{equation}
\todo{effect??}

\subsection*{Zero-to-node formulation}
Recursively applying the node-to-node collocation equations provides the zero-to-node formulation for both standard and embedded quadrature rules
...

\section*{Scalar test problem}
We consider the following simplified test problem to study stability and accuracy
\begin{equation}
	\begin{pmatrix} \dot{y}_1 \\ \dot{y}_2 \end{pmatrix} = \nu \begin{pmatrix} y_1 \\ y_2 \end{pmatrix} + \begin{pmatrix} a \left( y_1 - y_2 \right) \\ -a (y_1 - y_2) \end{pmatrix}
		= \begin{pmatrix}  \nu + a & -a \\ -a & \nu  +a \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}
\end{equation}
assuming that both machine parts have the same heat transport coefficient $\nu$.
The eigenvalues are the roots of
\begin{align*}
	\left| \begin{pmatrix}  \nu + a & -a \\ -a & \nu  +a \end{pmatrix} - \lambda \ve{I} \right| &= \left( \nu + a - \lambda \right)^2 - a^2 \\
	&= \left( \nu + a \right)^2 - 2 \lambda \left( \nu + a \right) + \lambda^2 - a^2 = 0
\end{align*}
so that
\begin{equation}
	\lambda_{1,2} = \nu + a \pm \sqrt{ \left(\nu+a\right)^2 + a^2 - \left( \nu + a \right)^2 } = \nu + a \pm \left| a \right|.
\end{equation}
Assume that $a > 0$ so that
\begin{equation}
	\lambda_1 = \nu \ \text{and} \ \lambda_2 = \nu + 2 a.
\end{equation}
The matrix can be diagonalised as
\begin{equation}
	\begin{pmatrix} \nu+a & -a \\ -a & \nu + a \end{pmatrix} = \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} \nu & 0 \\ 0 & \nu + 2 a \end{pmatrix} \begin{pmatrix} \frac{1}{2} & \frac{1}{2} \\ -\frac{1}{2} & \frac{1}{2} \end{pmatrix} =: S D S^{-1}.
\end{equation}
For some initial value $\ve{y}_0$, the solution $\ve{y} := (y_1, y_2)$ can be found from
\begin{equation}
	\dot{\ve{z}} = D \ve{z}, \ \ve{z}(0) = S^{-1} \ve{y}_0 = \begin{pmatrix} \frac{1}{2} y_1(0) + \frac{1}{2} y_2(0) \\ -\frac{1}{2} y_1(0) + \frac{1}{2} y_2(0) \end{pmatrix}
\end{equation}
by computing $\ve{y} = S \ve{z}$.
It is straightforward to compute
\begin{equation}
	\ve{z} = \begin{pmatrix} z_1(t) \\ z_2(t) \end{pmatrix} = \begin{pmatrix} z_1(0) e^{\nu t} \\ z_2(0) e^{\left(\nu + 2a\right)t} \end{pmatrix} = \begin{pmatrix} \frac{1}{2} \left(y_1(0) + y_2(0) \right) e^{\nu t} \\ \frac{1}{2} \left( y_2(0) - y_1(0) \right) e^{(\nu + 2 a) t} \end{pmatrix}
\end{equation}
and then
\begin{equation}
	\ve{y} = S \ve{z} = \begin{pmatrix} z_{1}(t) - z_{2}(t) \\ z_{1}(t) + z_{2}(t) \end{pmatrix} = \frac{1}{2}  \begin{pmatrix}  y_1(0) + y_2(0)  \\ y_1(0) + y_2(0) \end{pmatrix} e^{\nu t} + \frac{1}{2} \begin{pmatrix} y_1(0) - y_2(0)   \\ y_2(0) - y_1(0) \end{pmatrix} e^{(\nu+2 a)t}
\end{equation}

\paragraph{Stability.}
To assess stability, we need to find a matrix $\ve{R}$ such that
\begin{equation}
	\ve{y}^1 = \ve{R} \ve{y}_0
\end{equation}
for a single time step of length $1$.
If $\sigma(\ve{R}) \leq 1$, the series generated from repeatedly applying $\ve{R}$ won't diverge and the method is stable.
\end{document}